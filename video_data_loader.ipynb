{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "program_root_dir/\n",
    "    video_data_loader.ipynb\n",
    "    read_datasetBreakfast.py\n",
    "    test_segment.txt\n",
    "    training_segment.txt\n",
    "    \n",
    "    splits/\n",
    "        mapping_bf.txt\n",
    "        train.split1.bundle\n",
    "        test.split1.bundle\n",
    "        \n",
    "    groundTruth/\n",
    "        P16_cam01_P16_cereals.txt\n",
    "            ...\n",
    "        P54_webcam02_P54_tea.txt\n",
    "        \n",
    "    data/\n",
    "        P03_cam01_P03_cereals.gz\n",
    "            ...\n",
    "        P54_webcam02_P54_tea.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T16:17:25.547169Z",
     "start_time": "2020-03-29T16:17:23.731755Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import os.path \n",
    "from read_datasetBreakfast import read_mapping_dict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: define data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T16:17:27.873103Z",
     "start_time": "2020-03-29T16:17:27.867145Z"
    }
   },
   "outputs": [],
   "source": [
    "train_split =  'splits/train.split1.bundle' # Train Split file\n",
    "test_split  =  'splits/test.split1.bundle' # Test Split file\n",
    "GT_folder   =  'groundTruth/' # Ground Truth Labels for each training video \n",
    "DATA_folder =  'data/' # Frame I3D features for all videos\n",
    "mapping_loc =  'splits/mapping_bf.txt' # mapping from string label to int label\n",
    "train_segment = 'training_segment.txt'\n",
    "test_segment = \"test_segment.txt\"\n",
    "\n",
    "actions_dict = read_mapping_dict(mapping_loc)  # a dict contains mapping from string label to int label\n",
    "validation_videos = 60  # how many videos are used for validation (must < 1460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: define dataset (only load a video when you need it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T16:18:33.011209Z",
     "start_time": "2020-03-29T16:18:32.995335Z"
    }
   },
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, type=\"train\",  deleteSIL=False):\n",
    "        \"\"\"\n",
    "            type: \"train\", \"validation\" or \"test\"\n",
    "            deleteSIL: only works for train or validation videos: delete background frames based on labels\n",
    "        \"\"\"\n",
    "        self.type = type\n",
    "        self.deleteSIL = deleteSIL\n",
    "        self.videofiles = []\n",
    "        self.videosegments = []\n",
    "        self.split_file = test_split if type == \"test\" else train_split\n",
    "        self.segment_file = test_segment if type == \"test\" else train_segment\n",
    "         \n",
    "        with open(self.split_file, 'r') as file:\n",
    "            videofiles = file.read().split('\\n')[1:-1]\n",
    "            # 删掉前缀，只保留文件名，返回所有train video的名字list\n",
    "            self.videofiles = [x.strip('./data/groundTruth/') + 't' for x in videofiles]  \n",
    "        \n",
    "        # read segments for test videos\n",
    "        with open(self.segment_file, 'r') as file:\n",
    "            vs = file.read().split('\\n')[: -1]\n",
    "            self.videosegments = [torch.tensor(list(map(int, seg.split()))) for seg in vs]\n",
    "\n",
    "        if type == \"train\":\n",
    "            self.videofiles = self.videofiles[validation_videos: len(self.videofiles)]\n",
    "            self.videosegments = self.videosegments[validation_videos: len(self.videosegments)]\n",
    "        elif type == \"validation\":\n",
    "            self.videofiles = self.videofiles[:validation_videos]\n",
    "            self.videosegments = self.videosegments[:validation_videos]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.videofiles)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            :If train or validation, return a tuple (video_feature_tensor, shape: [N*400], label_tensor, shape: [N], video_segments, shape: [S])\n",
    "                N 是该视频中的frame数目, S为分段节点的数目\n",
    "            :If test（即测试数据集）, only return (video_feature_tensor, video_segments)\n",
    "        \"\"\"\n",
    "        content = self.videofiles[index]\n",
    "        \n",
    "        # read labels\n",
    "        data_breakfast = None\n",
    "        labels_breakfast = None\n",
    "        \n",
    "        # For train or validation video, load lables\n",
    "        if self.type != \"test\":  \n",
    "            with open(GT_folder + content, 'r') as label_file:\n",
    "                curr_gt = label_file.read().split('\\n')[:-1]  # read label for each frame\n",
    "                label_curr_video = []    # 按照dict把文本标签转换为数字\n",
    "                for iik in range(len(curr_gt)):\n",
    "                    label_curr_video.append(actions_dict[curr_gt[iik]])\n",
    "                labels_breakfast = torch.tensor(label_curr_video)\n",
    "                \n",
    "        # read video feature for this video \n",
    "        loc_curr_data = DATA_folder + os.path.splitext(content)[0] + '.gz'\n",
    "        curr_data = np.loadtxt(loc_curr_data, dtype='float32')  # read features for a specific video\n",
    "        data_breakfast = torch.tensor(curr_data,  dtype=torch.float64 )\n",
    "        \n",
    "        # delete background frames\n",
    "        if self.type != \"test\" and self.deleteSIL:\n",
    "            mask = labels_breakfast != 0\n",
    "            data_breakfast = data_breakfast[mask]\n",
    "            labels_breakfast = labels_breakfast[mask]\n",
    "            \n",
    "        return (data_breakfast, labels_breakfast, self.videosegments[index]) if self.type != \"test\" else (data_breakfast, self.videosegments[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: define dataset and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T16:18:39.775522Z",
     "start_time": "2020-03-29T16:18:36.534681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) 1400\n",
      "len(valid_dataset) 60\n",
      "len(test_dataset) 252\n",
      "train feature shape: torch.Size([7910, 400]) ; lable shape: torch.Size([7910])\n",
      "validation feature shape: torch.Size([544, 400]) ; lable shape: torch.Size([544])\n",
      "test feature shape: torch.Size([832, 400])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VideoDataset(type=\"train\")\n",
    "print(\"len(train_dataset)\", len(train_dataset))\n",
    "valid_dataset = VideoDataset(type=\"validation\")\n",
    "print(\"len(valid_dataset)\", len(valid_dataset))\n",
    "test_dataset = VideoDataset(type=\"test\")\n",
    "print(\"len(test_dataset)\", len(test_dataset))\n",
    "\n",
    "train_video0, label_train_video0, train_seg = train_dataset[0]\n",
    "print(\"train feature shape:\", train_video0.shape, \"; lable shape:\", label_train_video0.shape)\n",
    "valid_video0, label_valid_video0, valid_seg = valid_dataset[0]\n",
    "print(\"validation feature shape:\", valid_video0.shape, \"; lable shape:\", label_valid_video0.shape)\n",
    "test_video0, test_seg = test_dataset[0]\n",
    "print(\"test feature shape:\", test_video0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T16:18:45.265597Z",
     "start_time": "2020-03-29T16:18:45.229420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  9, 269, 474]) torch.Size([3])\n",
      "tensor(9)\n",
      "tensor(0) tensor(1) tensor(1)\n",
      "tensor(269)\n",
      "tensor(1) tensor(2) tensor(2)\n",
      "tensor(474)\n",
      "tensor(2) tensor(0) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# check segment information\n",
    "print(valid_seg, valid_seg.shape)\n",
    "for i in range(valid_seg.shape[0]):\n",
    "    print(valid_seg[i])\n",
    "    print(label_valid_video0[valid_seg[i]-1], label_valid_video0[valid_seg[i]], label_valid_video0[valid_seg[i]+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T11:17:38.408105Z",
     "start_time": "2020-03-26T11:17:38.405140Z"
    }
   },
   "source": [
    "## Step 4: define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T16:19:52.027825Z",
     "start_time": "2020-03-29T16:19:51.784785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 731, 400]), torch.Size([1, 731]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意，因为每个视频的帧数不同，所以 batch_size>1 时会报错\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "train_batch_video, train_batch_label, train_seg = next(iter(trainloader))\n",
    "train_batch_video.shape, train_batch_label.shape, train_seg.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
