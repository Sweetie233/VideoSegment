{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "program_root_dir/\n",
    "    video_data_loader.ipynb\n",
    "    read_datasetBreakfast.py\n",
    "    test_segment.txt\n",
    "    training_segment.txt\n",
    "    \n",
    "    splits/\n",
    "        mapping_bf.txt\n",
    "        train.split1.bundle\n",
    "        test.split1.bundle\n",
    "        \n",
    "    groundTruth/\n",
    "        P16_cam01_P16_cereals.txt\n",
    "            ...\n",
    "        P54_webcam02_P54_tea.txt\n",
    "        \n",
    "    data/\n",
    "        P03_cam01_P03_cereals.gz\n",
    "            ...\n",
    "        P54_webcam02_P54_tea.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T11:29:19.404204Z",
     "start_time": "2020-03-26T11:29:19.005695Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import os.path \n",
    "from read_datasetBreakfast import read_mapping_dict\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: define data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T11:29:19.409079Z",
     "start_time": "2020-03-26T11:29:19.405061Z"
    }
   },
   "outputs": [],
   "source": [
    "train_split =  'splits/train.split1.bundle' # Train Split file\n",
    "test_split  =  'splits/test.split1.bundle' # Test Split file\n",
    "GT_folder   =  'groundTruth/' # Ground Truth Labels for each training video \n",
    "DATA_folder =  'data/' # Frame I3D features for all videos\n",
    "mapping_loc =  'splits/mapping_bf.txt' # mapping from string label to int label\n",
    "\n",
    "actions_dict = read_mapping_dict(mapping_loc)  # a dict contains mapping from string label to int label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: define dataset (only load a video when you need it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T11:29:19.424014Z",
     "start_time": "2020-03-26T11:29:19.411045Z"
    }
   },
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, train=True, deleteSIL=True):\n",
    "        \"\"\"\n",
    "            train: -> True to load train videos, False to load test videos\n",
    "            deleteSIL -> only works for train videos: delete background frames based on labels\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        self.deleteSIL = deleteSIL\n",
    "        \n",
    "        self.videofiles = []\n",
    "        self.split_file = train_split if train else test_split\n",
    "        with open(self.split_file, 'r') as file:\n",
    "            videofiles = file.read().split('\\n')[1:-1]\n",
    "            # 删掉前缀，只保留文件名，返回所有train video的名字list\n",
    "            self.videofiles = [x.strip('./data/groundTruth/') + 't' for x in videofiles]  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videofiles)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "            If train is True, return a tuple (video_feature_tensor, shape: [N*400], label_tensor, shape: [N])\n",
    "                -> N 是该视频中的frame数目\n",
    "            If train is False（即测试数据集）, only return video_feature_tensor\n",
    "        \"\"\"\n",
    "        content = self.videofiles[index]\n",
    "        \n",
    "        # read labels\n",
    "        data_breakfast = None\n",
    "        labels_breakfast = None\n",
    "        \n",
    "        # For train video, load lables\n",
    "        if self.train:  \n",
    "            with open(GT_folder + content, 'r') as label_file:\n",
    "                curr_gt = label_file.read().split('\\n')[:-1]  # read label for each frame\n",
    "                label_curr_video = []    # 按照dict把文本标签转换为数字\n",
    "                for iik in range(len(curr_gt)):\n",
    "                    label_curr_video.append(actions_dict[curr_gt[iik]])\n",
    "                labels_breakfast = torch.tensor(label_curr_video)\n",
    "                \n",
    "        # read video feature for this video \n",
    "        loc_curr_data = DATA_folder + os.path.splitext(content)[0] + '.gz'\n",
    "        curr_data = np.loadtxt(loc_curr_data, dtype='float32')  # read features for a specific video\n",
    "        data_breakfast = torch.tensor(curr_data,  dtype=torch.float64 )\n",
    "        \n",
    "        # delete background frames\n",
    "        if self.train and self.deleteSIL:\n",
    "            mask = labels_breakfast != 0\n",
    "            data_breakfast = data_breakfast[mask]\n",
    "            labels_breakfast = labels_breakfast[mask]\n",
    "            \n",
    "        return (data_breakfast, labels_breakfast) if self.train else data_breakfast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: define dataset and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T11:29:19.771081Z",
     "start_time": "2020-03-26T11:29:19.425033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) 1460\n",
      "len(test_dataset) 252\n",
      "train feature shape: torch.Size([465, 400]) ; lable shape: torch.Size([465])\n",
      "test feature shape: torch.Size([832, 400])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VideoDataset()\n",
    "print(\"len(train_dataset)\", len(train_dataset))\n",
    "test_dataset = VideoDataset(train=False)\n",
    "print(\"len(test_dataset)\", len(test_dataset))\n",
    "\n",
    "train_video0, label_train_video0 = train_dataset[0]\n",
    "print(\"train feature shape:\", train_video0.shape, \"; lable shape:\", label_train_video0.shape)\n",
    "test_video0 = test_dataset[0]\n",
    "print(\"test feature shape:\", test_video0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T11:17:38.408105Z",
     "start_time": "2020-03-26T11:17:38.405140Z"
    }
   },
   "source": [
    "## Step 4: define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T11:29:19.944617Z",
     "start_time": "2020-03-26T11:29:19.772079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 682, 400]), torch.Size([1, 682]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意，因为每个视频的帧数不同，所以 batch_size>1 时会报错\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "train_batch_video, train_batch_label = next(iter(trainloader))\n",
    "train_batch_video.shape, train_batch_label.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
